{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=False)\n",
    "mnist = input_data.read_data_sets('data/fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(10)]) - 1\n",
    "    for d in range(10):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i+1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, 10)\n",
    "            dn = (d + inc) % 10\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp(input_, input_dim, output_dim, name=\"mlp\"):\n",
    "    with tf.variable_scope(name):\n",
    "        w = tf.get_variable('w',[input_dim,output_dim],tf.float32,tf.random_normal_initializer(mean = 0.001,stddev=0.02))\n",
    "        return tf.nn.relu(tf.matmul(input_,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_mlp(X_, _dropout, model_type='m1'):\n",
    "    if model_type == 'm1':\n",
    "        l1 = mlp(X_,784,128,name='l1')\n",
    "        l1 = tf.nn.dropout(l1,_dropout)\n",
    "        l2 = mlp(l1,128,128,name='l2')\n",
    "        l2 = tf.nn.dropout(l2,_dropout)\n",
    "        l3 = mlp(l2,128,128,name='l3')\n",
    "        return l3\n",
    "    elif model_type == 'm2':\n",
    "        l1 = mlp(X_,784,128,name='l1')\n",
    "        l1 = tf.nn.dropout(l1,_dropout)\n",
    "        l2 = mlp(l1,128,128,name='l2')\n",
    "        l2 = tf.nn.dropout(l2,_dropout)\n",
    "        l3 = mlp(l2,128,128,name='l3')\n",
    "        l3 = tf.nn.dropout(l3,_dropout)\n",
    "        l4 = mlp(l3,128,128,name='l4')\n",
    "        return l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y, d, batch_size):\n",
    "    tmp = y *tf.square(d)\n",
    "    #tmp= tf.mul(y,tf.square(d))\n",
    "    tmp2 = (1-y) * tf.square(tf.maximum((1 - d),0))\n",
    "    return tf.reduce_sum(tmp +tmp2)/batch_size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(prediction, labels):\n",
    "    return labels[prediction.ravel() < 0.5].mean()\n",
    "    #return tf.reduce_mean(labels[prediction.ravel() < 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(s, e, inputs, labels):\n",
    "    input1 = inputs[s:e, 0]\n",
    "    input2 = inputs[s:e, 1]\n",
    "    y= np.reshape(labels[s:e], (len(range(s, e)), 1))\n",
    "    return input1, input2, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model1, model2, images_L, images_R):\n",
    "    X_train = mnist.train._images\n",
    "    y_train = mnist.train._labels\n",
    "    X_test = mnist.test._images\n",
    "    y_test = mnist.test._labels\n",
    "    batch_size = 128\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 10, 0.1,  staircase=True)\n",
    "\n",
    "    # create training+test positive and negative pairs:\n",
    "    digit_indices = [np.where(y_train == i)[0] for i in range(10)]\n",
    "    tr_pairs, tr_y = create_pairs(X_train, digit_indices)\n",
    "    digit_indices = [np.where(y_test == i)[0] for i in range(10)]\n",
    "    te_pairs, te_y = create_pairs(X_test, digit_indices)\n",
    "    labels = tf.placeholder(tf.float32,shape=([None,1]),name='gt')\n",
    "\n",
    "    # set distance layer\n",
    "    distance  = tf.sqrt(tf.reduce_sum(tf.pow(tf.subtract(model1,model2),2),1,keep_dims=True))\n",
    "    \n",
    "    loss = contrastive_loss(labels, distance, batch_size)\n",
    "    # contrastice loss:\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars  = [var for var in t_vars if 'l' in var.name]\n",
    "    batch = tf.Variable(0)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(loss)\n",
    "\n",
    "    # Create a summary to monitor cost tensor\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    # Create a summary to monitor accuracy tensor\n",
    "    #tf.summary.scalar(\"accuracy\", acc)\n",
    "    # Merge all summaries into a single op\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    # Launch the graph:\n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(init)\n",
    "        tf.initialize_all_variables().run()\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "        # Training cycle:\n",
    "        for epoch in range(10):\n",
    "            avg_loss = 0.\n",
    "            avg_acc = 0.\n",
    "            total_batch = int(X_train.shape[0]/batch_size)\n",
    "            start_time = time.time()\n",
    "            # Loop over all batches:\n",
    "            for i in range(total_batch):\n",
    "                s = i * batch_size\n",
    "                e = (i+1) * batch_size\n",
    "                # Fit training using batch data:\n",
    "                input1, input2, y = next_batch(s, e, tr_pairs, tr_y)\n",
    "                _, loss_value, predict, summary = sess.run([optimizer, loss, distance, merged_summary_op], \n",
    "                                                           feed_dict={images_L:input1, images_R:input2, labels:y, dropout_f:0.9})\n",
    "                feature1 = model1.eval(feed_dict={images_L:input1, dropout_f:0.9})\n",
    "                feature2 = model2.eval(feed_dict={images_R:input2, dropout_f:0.9})\n",
    "                tr_acc = compute_accuracy(predict, y)\n",
    "                if math.isnan(tr_acc) and epoch != 0:\n",
    "                    print('tr_acc %0.2f' % tr_acc)\n",
    "                    \n",
    "                avg_loss += loss_value\n",
    "                avg_acc += tr_acc*100\n",
    "            #print('epoch %d loss %0.2f' %(epoch,avg_loss/total_batch))\n",
    "            duration = time.time() - start_time\n",
    "            summary_writer.add_summary(summary, epoch)\n",
    "            print('Epoch %d  time: %f loss %0.5f acc %0.2f' %(epoch, duration, avg_loss/(total_batch), avg_acc/total_batch))\n",
    "            \n",
    "        y = np.reshape(tr_y, (tr_y.shape[0], 1))\n",
    "        predict = distance.eval(feed_dict={images_L:tr_pairs[:, 0], images_R:tr_pairs[:, 1], labels:y, dropout_f:1.0})\n",
    "        tr_acc = compute_accuracy(predict, y)\n",
    "        print('Accuracy on training set %0.2f' % (100 * tr_acc))\n",
    "\n",
    "        # Test model:\n",
    "        predict = distance.eval(feed_dict={images_L:te_pairs[:, 0], images_R:te_pairs[:, 1], labels:y, dropout_f:1.0})\n",
    "        y = np.reshape(te_y, (te_y.shape[0], 1))\n",
    "        te_acc = compute_accuracy(predict, y)\n",
    "    print('Accuracy on test set %0.2f' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initializing the variables:\n",
    "init = tf.global_variables_initializer()\n",
    "logs_path = \"./siamese-logs/\"\n",
    "\n",
    "images_L = tf.placeholder(tf.float32,shape=([None,784]),name='L')\n",
    "images_R = tf.placeholder(tf.float32,shape=([None,784]),name='R')\n",
    "dropout_f = tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0  time: 11.759466 loss 0.09413 acc 70.20\n",
      "Epoch 1  time: 11.815649 loss 0.06534 acc 80.72\n",
      "Epoch 2  time: 11.868871 loss 0.05345 acc 86.05\n",
      "Epoch 3  time: 11.806733 loss 0.04554 acc 89.41\n",
      "Epoch 4  time: 12.173197 loss 0.03922 acc 91.60\n",
      "Epoch 5  time: 11.856660 loss 0.03446 acc 93.25\n",
      "Epoch 6  time: 11.631263 loss 0.03084 acc 94.24\n",
      "Epoch 7  time: 11.995389 loss 0.02775 acc 95.09\n",
      "Epoch 8  time: 11.895437 loss 0.02522 acc 95.87\n",
      "Epoch 9  time: 11.898722 loss 0.02324 acc 96.48\n",
      "Accuracy on training set 90.48\n",
      "Accuracy on test set 90.48\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"siamese_model1\") as scope:\n",
    "    m1_net_1 = build_model_mlp(images_L, dropout_f, 'm1')\n",
    "    scope.reuse_variables()\n",
    "    m1_net_2 = build_model_mlp(images_R, dropout_f, 'm1')\n",
    "train_and_test(m1_net_1, m1_net_2, images_L, images_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch 0  time: 13.246230 loss 0.11343 acc 65.29\n",
      "Epoch 1  time: 13.486138 loss 0.07500 acc 76.06\n",
      "Epoch 2  time: 13.503401 loss 0.05956 acc 81.92\n",
      "Epoch 3  time: 13.640658 loss 0.05192 acc 84.77\n",
      "Epoch 4  time: 13.366747 loss 0.04579 acc 87.22\n",
      "Epoch 5  time: 13.340147 loss 0.04150 acc 88.71\n",
      "Epoch 6  time: 13.224046 loss 0.03855 acc 89.68\n",
      "Epoch 7  time: 13.370544 loss 0.03569 acc 90.56\n",
      "Epoch 8  time: 13.281561 loss 0.03354 acc 91.44\n",
      "Epoch 9  time: 13.340416 loss 0.03152 acc 92.00\n",
      "Accuracy on training set 80.09\n",
      "Accuracy on test set 80.00\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"siamese_model2\") as scope:\n",
    "    m2_net_1 = build_model_mlp(images_L, dropout_f, 'm2')\n",
    "    scope.reuse_variables()\n",
    "    m2_net_2 = build_model_mlp(images_R, dropout_f, 'm2')\n",
    "train_and_test(m2_net_1, m2_net_2, images_L, images_R)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
